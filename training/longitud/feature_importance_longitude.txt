Explained as: feature importances

Feature importances, computed as a decrease in score when feature
values are permuted (i.e. become noise). This is also known as 
permutation importance.

If feature importances are computed on the same data as used for training, 
they don't reflect importance of features for generalization. Use a held-out
dataset if you want generalization feature importances.

360.5150 ± 20.5582  lat_lon_interaction
310.0188 ± 7.7036  latitude
2.5097 ± 0.0278  magType_mb
1.7779 ± 0.0230  magSource_guc
1.5831 ± 0.0515  locationSource_guc
1.3400 ± 0.0271  locationSource_us
1.2299 ± 0.0111  magSource_us
1.0441 ± 0.0136  magType_md
0.6698 ± 0.0329  magType_mwr
0.6571 ± 0.0345  magType_ml
0.4702 ± 0.0239  year
0.4123 ± 0.0129  time_numeric
0.2202 ± 0.0103  magType_mww
0.1754 ± 0.0112  magType_mwc
0.1504 ± 0.0121  magType_m
0.0626 ± 0.0087  magSource_gcmt
0.0453 ± 0.0029  dmin
0.0308 ± 0.0061  magType_mwb
0.0150 ± 0.0036  locationSource_sja
0.0149 ± 0.0028  magSource_hrv
              … 22 more …              